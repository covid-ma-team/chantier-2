{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate fake data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys, os\n",
    "import math\n",
    "import urllib.request\n",
    "\n",
    "import folium # last version 0.11.0\n",
    "from folium import plugins\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Morocco geojson (replace with the correct one)\n",
    "# We will generate points insde list of regions \n",
    "\n",
    "morocco_map = gpd.read_file('./datasets/maroc.geojson')\n",
    "regions_map = gpd.read_file('./datasets/regions.geojson')\n",
    "communes_map = gpd.read_file('./datasets/communes.geojson')\n",
    "irfane_map = gpd.read_file('./datasets/irfane.geojson')\n",
    "\n",
    "morocco_polygon = morocco_map[\"geometry\"][0]\n",
    "regions_polygons = regions_map[\"geometry\"]\n",
    "\n",
    "irfane_polygon = irfane_map[\"geometry\"]\n",
    "regions_polygons[0].centroid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a dictionaty data structure of user's latitude, longitude and score over time inside a list of regions\n",
    "# input the initial position, the number of users, radius (chose a big radius to cover big regions), \n",
    "# time (integer), and list of the polygons of the regions\n",
    "def generate_random_data(init_longitude = 0.0, init_latitude = 0.0, radius = 5, num_users = 1, time = 1, list_polygons = None):\n",
    "    data = {}\n",
    "    #cumuleScoreDict = {}\n",
    "    for ts in np.arange(time):\n",
    "        new_ts = {}\n",
    "        for uid in np.arange(num_users):\n",
    "\n",
    "            u = random.random()\n",
    "            v = random.random()\n",
    "            w = radius * np.sqrt(u)\n",
    "            t = 2 * np.pi * v\n",
    "            epsilon_longitude = w * np.sin(t)\n",
    "            epsilon_latitude = w * np.cos(t) \n",
    "            \n",
    "            # costruct new point\n",
    "            new_longitude = init_longitude + epsilon_longitude\n",
    "            new_latitude = init_latitude + epsilon_latitude\n",
    "            \n",
    "            #check if the constructed point is inside region_polygon\n",
    "            new_point = Point(new_latitude, new_longitude)\n",
    "\n",
    "            randomScore = random.random()\n",
    "            \n",
    "            idx_poly = contains(list_polygons, new_point)\n",
    "            \n",
    "            if idx_poly != None:\n",
    "                new_longitude = init_longitude + epsilon_longitude\n",
    "                new_latitude = init_latitude + epsilon_latitude\n",
    "            else: # just keep initial position\n",
    "                new_longitude = init_longitude\n",
    "                new_latitude = init_latitude\n",
    "            \n",
    "            # create user data\n",
    "            new_uid = {\n",
    "                #\"uid\":uid,\n",
    "                \"longitude\": new_longitude, \n",
    "                \"latitude\": new_latitude, \n",
    "                \"score\":randomScore,\n",
    "                \"idx_poly\": idx_poly\n",
    "                }\n",
    "            new_ts[\"uid\" + str(uid)] = new_uid\n",
    "                \n",
    "        # append timestamp\n",
    "        data[str(ts)] = new_ts\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if of the gerated point is inside a list of polygons\n",
    "def contains(list_polygons, point):\n",
    "    for idx_poly, polygon in enumerate(list_polygons):\n",
    "        if polygon.contains(point):\n",
    "            return idx_poly\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region of interest\n",
    "#Test 0: Chose all morocco\n",
    "LIST_POLYGONS  = [morocco_polygon]\n",
    "#Test 1: Chose from the twelve regions\n",
    "#  Tanger (0),Oujda (1),Rabat (2), (3), Casa (4), BeniMellal(5), Marakech(6), Errachidia(7), ...\n",
    "LIST_POLYGONS  = [regions_polygons[4], regions_polygons[2]]\n",
    "# Test 2: chose irfane region\n",
    "LIST_POLYGONS  = irfane_polygon\n",
    "\n",
    "# initial Points  (Rabat)\n",
    "INIT_LONGITUDE = LIST_POLYGONS[1].centroid.y\n",
    "INIT_LATITUDE  = LIST_POLYGONS[1].centroid.x\n",
    "\n",
    "# simulation parameters\n",
    "NUM_USERS = 1000\n",
    "TIME = 50 # in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "data = generate_random_data( \n",
    "    init_longitude = INIT_LONGITUDE, \n",
    "    init_latitude = INIT_LATITUDE,\n",
    "    radius = .05, # radius tested: 0.05 for Irfane, 5 for regions, 15 for Morocco\n",
    "    num_users = NUM_USERS, \n",
    "    time = TIME,\n",
    "    list_polygons = LIST_POLYGONS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Cholorpleth With Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to prapare data structure for this task\n",
    "data_polygons = [[[0 for k in np.zeros(3)] for j in np.zeros(len(LIST_POLYGONS))] for i in np.zeros(TIME)]\n",
    "\n",
    "for ts in np.arange(TIME):\n",
    "    for key, value in data[str(ts)].items():\n",
    "        idx_poly = value['idx_poly']\n",
    "        if idx_poly != None:\n",
    "            data_polygons[ts][idx_poly][0] = LIST_POLYGONS[idx_poly].centroid.y #longitude\n",
    "            data_polygons[ts][idx_poly][1] = LIST_POLYGONS[idx_poly].centroid.x #latitude\n",
    "            data_polygons[ts][idx_poly][2] += value['score'] # cumulative score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_lon_roi, med_lat_roi, med_score_roi = np.median(np.median(np.array(data_polygons), 1), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./datasets/irfane.geojson') as f:\n",
    "    geojson_irfane = json.load(f)\n",
    "\n",
    "#geojson_irfane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for idx, i in enumerate(geojson_irfane['features']):\n",
    "    ids.append(i['properties']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "all_data_cholorpleth = []\n",
    "for t in np.arange(TIME):\n",
    "    data_cholorpleth = pd.DataFrame.from_records(data_polygons[t], columns=[\"longitude\", \"latitude\", \"cumul_score\"])\n",
    "    data_cholorpleth['id'] = ids\n",
    "    \n",
    "    #Normalize scores\n",
    "    cs = data_cholorpleth[['cumul_score']].values #returns a numpy array\n",
    "    cumul_score_scaled = scaler.fit_transform(cs) \n",
    "    data_cholorpleth[\"cumul_score_scaled\"] = pd.DataFrame(cumul_score_scaled)\n",
    "    \n",
    "    all_data_cholorpleth.append(data_cholorpleth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#chose timestamp (between 0 and TIME)\n",
    "t = 10\n",
    "assert t < TIME and t >= 0\n",
    "\n",
    "# map   \n",
    "map_irfane_choropleth = folium.Map([med_lon_roi, med_lat_roi],  zoom_start=14)\n",
    "\n",
    "# choropleth\n",
    "folium.Choropleth(\n",
    "    geo_data=geojson_irfane,\n",
    "    name='choropleth',\n",
    "    data=all_data_cholorpleth[t],\n",
    "    columns=['id', 'cumul_score_scaled'],\n",
    "    # see folium.Choropleth? for details on key_on\n",
    "    key_on='feature.properties.id',\n",
    "    fill_color='PuRd', # 'OrRd', 'PuBu', 'PuBuGn', 'PuRd', 'RdPu', 'YlGn', 'YlGnBu', 'YlOrBr', and 'YlOrRd'.\n",
    "    fill_opacity=0.8,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='score',\n",
    "    highlight=True\n",
    ").add_to(map_irfane_choropleth)\n",
    "\n",
    "# layer control to turn choropleth on or off\n",
    "folium.LayerControl().add_to(map_irfane_choropleth)\n",
    "\n",
    "# display map\n",
    "map_irfane_choropleth\n",
    "\n",
    "#save as html\n",
    "#map_irfane_choropleth.save(\"map\" + str(t) + \".html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View geojson Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geojson_path = './datasets/communes.geojson'\n",
    "#geojson_path = './datasets/regions.geojson'\n",
    "geojson_path = './datasets/maroc.geojson'\n",
    "\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[31.0, -6.0],\n",
    "    #tiles='Mapbox Bright',\n",
    "    zoom_start=5  # Limited levels of zoom for free Mapbox tiles.\n",
    ")\n",
    "\n",
    "folium.GeoJson(\n",
    "    geojson_path,\n",
    "    name='geojson'\n",
    ").add_to(m)\n",
    "\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate Tiles with Skmob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skmob.tessellation import tilers\n",
    "from skmob.utils import plot\n",
    "\n",
    "rabattessellation = tilers.tiler.get(\"squared\", base_shape=\"Rabat, Morocco\", meters=150)\n",
    "\n",
    "tess_style = {'color':'gray', 'fillColor':'gray', 'opacity':0.9}\n",
    "\n",
    "map_f = plot.plot_gdf(rabattessellation, zoom=14, popup_features=['id'], style_func_args=tess_style, tiles='Open Street Map')\n",
    "\n",
    "map_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmob.tessellation import tilers\n",
    "import osmnx as ox\n",
    "\n",
    "G = ox.graph_from_place('Beijing, China', which_result=2, network_type='drive')\n",
    "ox.plot_graph(G)\n",
    "\n",
    "nodes, _ = ox.graph_to_gdfs(G)\n",
    "nodes.head()\n",
    "\n",
    "tessellation = tilers.tiler.get(\"squared\", base_shape=nodes, meters=500)\n",
    "print(tessellation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('covidpylab': conda)",
   "language": "python",
   "name": "python37764bitcovidpylabconda9b82a304ca2b48b0ae4f7bc3f74ef588"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
